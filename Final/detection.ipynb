{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "RxPglMdkS-lb",
        "outputId": "ed0c7f07-44bc-4297-e585-a0bbb08ea5e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using Local Machine\n",
            "Cloning into 'yolov5'...\n",
            "remote: Enumerating objects: 16088, done.\u001b[K\n",
            "remote: Counting objects: 100% (32/32), done.\u001b[K\n",
            "remote: Compressing objects: 100% (30/30), done.\u001b[K\n",
            "remote: Total 16088 (delta 10), reused 14 (delta 2), pack-reused 16056\u001b[K\n",
            "Receiving objects: 100% (16088/16088), 14.71 MiB | 7.28 MiB/s, done.\n",
            "Resolving deltas: 100% (11038/11038), done.\n",
            "Collecting gitpython>=3.1.30 (from -r yolov5/requirements.txt (line 5))\n",
            "  Downloading GitPython-3.1.40-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.6/190.6 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=3.3 in /usr/local/lib/python3.10/dist-packages (from -r yolov5/requirements.txt (line 6)) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.22.2 in /usr/local/lib/python3.10/dist-packages (from -r yolov5/requirements.txt (line 7)) (1.23.5)\n",
            "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from -r yolov5/requirements.txt (line 8)) (4.8.0.76)\n",
            "Collecting Pillow>=10.0.1 (from -r yolov5/requirements.txt (line 9))\n",
            "  Downloading Pillow-10.1.0-cp310-cp310-manylinux_2_28_x86_64.whl (3.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m72.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from -r yolov5/requirements.txt (line 10)) (5.9.5)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from -r yolov5/requirements.txt (line 11)) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from -r yolov5/requirements.txt (line 12)) (2.31.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from -r yolov5/requirements.txt (line 13)) (1.11.4)\n",
            "Collecting thop>=0.1.1 (from -r yolov5/requirements.txt (line 14))\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from -r yolov5/requirements.txt (line 15)) (2.1.0+cu118)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from -r yolov5/requirements.txt (line 16)) (0.16.0+cu118)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from -r yolov5/requirements.txt (line 17)) (4.66.1)\n",
            "Collecting ultralytics>=8.0.147 (from -r yolov5/requirements.txt (line 18))\n",
            "  Downloading ultralytics-8.0.225-py3-none-any.whl (660 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m660.1/660.1 kB\u001b[0m \u001b[31m59.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from -r yolov5/requirements.txt (line 27)) (1.5.3)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from -r yolov5/requirements.txt (line 28)) (0.12.2)\n",
            "Requirement already satisfied: setuptools>=65.5.1 in /usr/local/lib/python3.10/dist-packages (from -r yolov5/requirements.txt (line 42)) (67.7.2)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython>=3.1.30->-r yolov5/requirements.txt (line 5))\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r yolov5/requirements.txt (line 6)) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r yolov5/requirements.txt (line 6)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r yolov5/requirements.txt (line 6)) (4.45.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r yolov5/requirements.txt (line 6)) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r yolov5/requirements.txt (line 6)) (23.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r yolov5/requirements.txt (line 6)) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r yolov5/requirements.txt (line 6)) (2.8.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r yolov5/requirements.txt (line 12)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r yolov5/requirements.txt (line 12)) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r yolov5/requirements.txt (line 12)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r yolov5/requirements.txt (line 12)) (2023.11.17)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r yolov5/requirements.txt (line 15)) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r yolov5/requirements.txt (line 15)) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r yolov5/requirements.txt (line 15)) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r yolov5/requirements.txt (line 15)) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r yolov5/requirements.txt (line 15)) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r yolov5/requirements.txt (line 15)) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r yolov5/requirements.txt (line 15)) (2.1.0)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics>=8.0.147->-r yolov5/requirements.txt (line 18)) (9.0.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->-r yolov5/requirements.txt (line 27)) (2023.3.post1)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython>=3.1.30->-r yolov5/requirements.txt (line 5))\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3->-r yolov5/requirements.txt (line 6)) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->-r yolov5/requirements.txt (line 15)) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->-r yolov5/requirements.txt (line 15)) (1.3.0)\n",
            "Installing collected packages: smmap, Pillow, gitdb, thop, gitpython, ultralytics\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: Pillow 9.4.0\n",
            "    Uninstalling Pillow-9.4.0:\n",
            "      Successfully uninstalled Pillow-9.4.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "imageio 2.31.6 requires pillow<10.1.0,>=8.3.2, but you have pillow 10.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Pillow-10.1.0 gitdb-4.0.11 gitpython-3.1.40 smmap-5.0.1 thop-0.1.1.post2209072238 ultralytics-8.0.225\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "try:\n",
        "    # from google.colab import drive\n",
        "    # drive.mount('/content/drive')\n",
        "    import zipfile\n",
        "    with zipfile.ZipFile('/content/drive/MyDrive/LisaDataset.zip', 'r') as zip_ref:\n",
        "        zip_ref.extractall('./LisaDataset')\n",
        "except:\n",
        "    print(\"Using Local Machine\")\n",
        "!git clone https://github.com/ultralytics/yolov5.git\n",
        "!pip install -r yolov5/requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "VdLSFpbFTMXz"
      },
      "outputs": [],
      "source": [
        "# Include all packages\n",
        "import os\n",
        "import cv2\n",
        "from time import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from yolov5.models.yolo import Model\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pycocotools.coco import COCO\n",
        "from pycocotools.cocoeval import COCOeval\n",
        "import torchvision\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "T6L3fz5FTVel"
      },
      "outputs": [],
      "source": [
        "\n",
        "def imgResize(img, x1, y1, x2, y2, newW, newH):\n",
        "    origHeight, origWidth = img.shape[:2]\n",
        "    scaleWidth = newW / origWidth\n",
        "    scaleHeight = newH / origHeight\n",
        "    imgResized = cv2.resize(\n",
        "        img, (newW, newH), interpolation=cv2.INTER_LINEAR)\n",
        "    newX1, newy1 = int(x1 * scaleWidth), int(y1 * scaleHeight)\n",
        "    newX2, newy2 = int(x2 * scaleWidth), int(y2 * scaleHeight)\n",
        "    return imgResized, newX1, newy1, newX2, newy2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "AiXMfveTTaRX"
      },
      "outputs": [],
      "source": [
        "def dsLoad(dsFolderPath):\n",
        "    imgs = []\n",
        "    annotations = []\n",
        "    filePathAnnotation = dsFolderPath+\"/allAnnotations.csv\"\n",
        "    dfAnnonation = pd.read_csv(filePathAnnotation, sep=\";\")\n",
        "    signsUnique = dfAnnonation['Annotation tag'].unique().tolist()\n",
        "    for index, row in dfAnnonation[1:].iterrows():\n",
        "        img = cv2.imread(dsFolderPath+\"/\"+row[0])\n",
        "        imgs.append(img)\n",
        "        annotations.append(\n",
        "            [signsUnique.index(row[1]), row[2], row[3], row[4], row[5]])\n",
        "\n",
        "    del dfAnnonation\n",
        "\n",
        "    return imgs, annotations, len(signsUnique)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "EyHVGLtFTcTM"
      },
      "outputs": [],
      "source": [
        "def dataPreProcess(imgs, annotations, batchSize, resize):\n",
        "    resizedImgs = []\n",
        "    newAnnotations = []\n",
        "    for i, img in enumerate(imgs):\n",
        "        [label, x1, y1, x2, y2] = annotations[i]\n",
        "        imgResized, newX1, newy1, newX2, newy2 = imgResize(\n",
        "            img, x1, y1, x2, y2, resize[0], resize[1])\n",
        "        resizedImgs.append(imgResized)\n",
        "        newAnnotations.append(\n",
        "            [(i % batchSize), label, newX1, newy1, newX2, newy2])\n",
        "\n",
        "    X_train, X_val, y_train, y_val = train_test_split(\n",
        "        resizedImgs, newAnnotations, test_size=0.3, random_state=42)\n",
        "\n",
        "    return X_train, X_val, y_train, y_val\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "1psd70akTemi"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, data, transform=None):\n",
        "        self.data = data\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        inputData, label = self.data[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            inputData = self.transform(inputData)\n",
        "        inputData = torch.from_numpy(inputData).float()\n",
        "        label = torch.tensor(label).float()\n",
        "        return inputData, label\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "_gCDejBCTgTj"
      },
      "outputs": [],
      "source": [
        "def dataLoadersCreation(X_train, X_val, y_train, y_val, batchSize):\n",
        "    dsTrain = []\n",
        "    dsVal = []\n",
        "    for i in range(len(X_train)):\n",
        "        dsTrain.append((X_train[i], y_train[i]))\n",
        "\n",
        "    for i in range(len(X_val)):\n",
        "        dsVal.append((X_val[i], y_val[i]))\n",
        "\n",
        "    dsTrain = CustomDataset(dsTrain)\n",
        "    dsVal = CustomDataset(dsVal)\n",
        "    DLTrain = DataLoader(\n",
        "        dsTrain, batchSize=batchSize, shuffle=True, num_workers=4)\n",
        "    DLVal = DataLoader(\n",
        "        dsVal, batchSize=batchSize, shuffle=False, num_workers=4)\n",
        "\n",
        "    return DLTrain, DLVal\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "k3AD4H0BTiBj"
      },
      "outputs": [],
      "source": [
        "\n",
        "def TargetToTensor(targets, batchSize, noAnchors, gridSizes, noClasses):\n",
        "    objTarget = []\n",
        "    objClass = []\n",
        "    boxTarget = []\n",
        "\n",
        "    for gridSize in gridSizes:\n",
        "        objTarget.append(torch.zeros(\n",
        "            (batchSize, noAnchors, gridSize, gridSize, 1)))\n",
        "        objClass.append(torch.zeros(\n",
        "            (batchSize, noAnchors, gridSize, gridSize, noClasses)))\n",
        "        boxTarget.append(torch.zeros(\n",
        "            (batchSize, noAnchors, gridSize, gridSize, 4)))\n",
        "\n",
        "    for target in targets:\n",
        "        batchIndex, cls, xCenter, yCenter, width, height = target.long()\n",
        "\n",
        "        for i, gridSize in enumerate(gridSizes):\n",
        "\n",
        "            xCell, yCell = int(\n",
        "                xCenter * gridSize), int(yCenter * gridSize)\n",
        "            anchor = 0\n",
        "            try:\n",
        "                objTarget[i][batchIndex, anchor, yCell, xCell, 0] = 1\n",
        "                objClass[i][batchIndex, anchor, yCell, xCell, cls] = 1\n",
        "                boxTarget[i][batchIndex, anchor, yCell, xCell] = torch.tensor(\n",
        "                    [xCenter, yCenter, width, height])\n",
        "            except Exception as e:\n",
        "                pass\n",
        "    return objTarget, objClass, boxTarget\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "RynVBxXGTu-8"
      },
      "outputs": [],
      "source": [
        "class YOLOv5Loss(nn.Module):\n",
        "    def __init__(self, noClasses, noAnchors=3):\n",
        "        super(YOLOv5Loss, self).__init__()\n",
        "        self.noClasses = noClasses\n",
        "        self.noAnchors = noAnchors\n",
        "\n",
        "    def forward(self, preds, targets):\n",
        "        lossobj = torch.tensor(0.0, device=preds[0].device)\n",
        "        lossClass = torch.tensor(0.0, device=preds[0].device)\n",
        "        lossBox = torch.tensor(0.0, device=preds[0].device)\n",
        "        batchSize = preds[0].size(0)\n",
        "        gridSizes = [pred.size(2) for pred in preds]\n",
        "        targetListObj, targetListClass, targetListBox = TargetToTensor(\n",
        "            targets, batchSize, self.noAnchors, gridSizes, self.noClasses)\n",
        "\n",
        "        for i, pred in enumerate(preds):\n",
        "            objTarget = targetListObj[i].to(pred.device)\n",
        "            objClass = targetListClass[i].to(pred.device)\n",
        "            boxTarget = targetListBox[i].to(pred.device)\n",
        "\n",
        "            lossobj += nn.BCEWithLogitsLoss()(pred[..., 4:5], objTarget)\n",
        "            lossClass += nn.BCEWithLogitsLoss()(pred[..., 5:], objClass)\n",
        "            lossBox += nn.MSELoss()(pred[..., :4], boxTarget)\n",
        "\n",
        "        lossTotal = lossobj + lossClass + lossBox\n",
        "        return lossTotal\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "RZ6Ayy1fT4hG"
      },
      "outputs": [],
      "source": [
        "def yolov5ModelCreation(noClasses, version=\"s\"):\n",
        "    configureFile = \"yolov5/models/yolov5{}.yaml\".format(version)\n",
        "    model = Model(configureFile, ch=3, nc=noClasses)\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "3R64NduoT7I7"
      },
      "outputs": [],
      "source": [
        "def TrainModel(model, dl, epochs, optimizer, lossFunction, device):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        print(\"Epoch {}/{}:\".format(epoch+1, epochs))\n",
        "        st = time()\n",
        "        lossTotal = 0\n",
        "        dLLen = len(dl)\n",
        "        for i, (inputs, targets) in enumerate(dl):\n",
        "            inputs = inputs.permute(0, 3, 1, 2)\n",
        "            inputs = inputs.to(device)\n",
        "            targets = targets.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            with torch.set_grad_enabled(True):\n",
        "                outputs = model(inputs)\n",
        "                loss = lossFunction(outputs, targets)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "            lossTotal += loss.item() * inputs.size(0)\n",
        "            if(((i*100)//dLLen) % 10 == 0):\n",
        "                print((i*100//dLLen), end=\"%,\")\n",
        "\n",
        "        et = time()\n",
        "        timeTaken = et-st\n",
        "        epochLoss = lossTotal / dLLen\n",
        "        print(\"Training Loss: {:.4f}\".format(epochLoss))\n",
        "        print(\"Time taken: {}min, {}, secs\".format(timeTaken//60, timeTaken % 60))\n",
        "\n",
        "    print(\"Training complete.\")\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "mMIKyf2sT85u"
      },
      "outputs": [],
      "source": [
        "def ProcessYoloOutput(outputs, shapeOfInput, conf_threshold=0.5, nms_threshold=0.5):\n",
        "    \n",
        "    predictions = []\n",
        "    for output in outputs:\n",
        "        # perform non-maximum suppression\n",
        "        box = output[:, :4]\n",
        "        scores = output[:, 4]\n",
        "        mask = scores >= conf_threshold\n",
        "        box = box[mask]\n",
        "        scores = scores[mask]\n",
        "        keep = torchvision.ops.box.batched_nms(\n",
        "            box, scores, torch.zeros_like(scores), nms_threshold)\n",
        "        box = box[keep]\n",
        "        scores = scores[keep]\n",
        "\n",
        "        box[:, [0, 2]] *= shapeOfInput[0]\n",
        "        box[:, [1, 3]] *= shapeOfInput[1]\n",
        "        box[:, [0, 2]] = box[:, [0, 2]].clamp(0, shapeOfInput[0] - 1)\n",
        "        box[:, [1, 3]] = box[:, [1, 3]].clamp(0, shapeOfInput[1] - 1)\n",
        "        box = box[:, [1, 0, 3, 2]]\n",
        "        conf = scores\n",
        "        for box, score in zip(box, conf):\n",
        "            predictions.append(\n",
        "                {'bbox': box.tolist(), 'score': score.item(), 'category_id': 1})\n",
        "\n",
        "    return predictions\n",
        "\n",
        "\n",
        "def mAPScore(preds, labels):\n",
        "    coco_gt = COCO()\n",
        "    for i, (image, box) in enumerate(labels):\n",
        "        for box in box:\n",
        "            x1, y1, x2, y2 = box\n",
        "            w, h = x2 - x1, y2 - y1\n",
        "            coco_gt.add_annotation({\n",
        "                'id': len(coco_gt.dataset['annotations']),\n",
        "                'image_id': i,\n",
        "                'category_id': 1,\n",
        "                'bbox': [x1, y1, w, h],\n",
        "                'area': w * h,\n",
        "                'iscrowd': 0,\n",
        "            })\n",
        "\n",
        "    # create a COCO-format predictions file\n",
        "    coco_dt = coco_gt.loadRes(preds)\n",
        "\n",
        "    # compute mAP using COCOeval\n",
        "    coco_eval = COCOeval(coco_gt, coco_dt, 'bbox')\n",
        "    coco_eval.evaluate()\n",
        "    coco_eval.accumulate()\n",
        "    coco_eval.summarize()\n",
        "\n",
        "    return coco_eval.stats[0]\n",
        "\n",
        "def EvaluateModel(model, dataLoader, device):\n",
        "    print(\"Evaluateing Model:\")\n",
        "    st = time()\n",
        "    dLLen = len(dataLoader)\n",
        "    mAPScore = 0\n",
        "    for i, (input, targets) in enumerate(dataLoader):\n",
        "        try:\n",
        "            input = input.permute(0, 3, 1, 2)\n",
        "            input = input.to(device)\n",
        "            targets = targets.to(device)\n",
        "            with torch.no_grad():\n",
        "                outputs = model(input)\n",
        "                preds = ProcessYoloOutput(outputs, input.shape)\n",
        "                print(preds)\n",
        "                mAPScore = mAPScore(preds, targets)\n",
        "        except:\n",
        "            pass\n",
        "        if(((i*100)//dLLen) % 10 == 0):\n",
        "            print((i*100//dLLen), end=\"%,\")\n",
        "\n",
        "    et = time()\n",
        "    timeTaken = et-st\n",
        "    print(\"mAP score on validation set: {:.4f}\".format(mAPScore))\n",
        "    print(\"Time taken: {}min, {}, secs\".format(timeTaken//60, timeTaken % 60))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "ILXzwYa4UAa0"
      },
      "outputs": [],
      "source": [
        "batchSize = 32\n",
        "shapeOfInput = (416, 416)\n",
        "epochs = 100\n",
        "noAnchors = 3\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gutrAh1pUBDg",
        "outputId": "ca30b07a-db6d-4813-917e-89e36e2ed6a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cuda device\n"
          ]
        }
      ],
      "source": [
        "print(\"Using {} device\".format(device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "TRCW55zMUCtO"
      },
      "outputs": [],
      "source": [
        "imgs, annotations, noClasses = dsLoad(\"/content/drive/MyDrive/LisaDataset\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "wKbOcTvjUEVU"
      },
      "outputs": [],
      "source": [
        "X_train, X_val, y_train, y_val = dataPreProcess(\n",
        "    imgs, annotations, batchSize, shapeOfInput)\n",
        "del imgs\n",
        "del annotations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Q2w98OrSXI8d"
      },
      "outputs": [],
      "source": [
        "DLTrain, DLVal = dataLoadersCreation(\n",
        "    X_train, X_val, y_train, y_val, batchSize)\n",
        "del X_train\n",
        "del y_train\n",
        "del X_val\n",
        "del y_val\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3we0DkaXLft",
        "outputId": "856eecca-de8a-4594-cb27-5ebb508cc1e3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Overriding model.yaml nc=80 with nc=47\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
            "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1    140244  yolov5.models.yolo.Detect               [47, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "YOLOv5s summary: 214 layers, 7146388 parameters, 7146388 gradients, 16.3 GFLOPs\n",
            "\n"
          ]
        }
      ],
      "source": [
        "yolov5Model = yolov5ModelCreation(noClasses)\n",
        "optimizer = optim.Adam(yolov5Model.parameters(), lr=0.001)\n",
        "yolov5LossFunction= YOLOv5Loss(noClasses=noClasses)\n",
        "yolov5Model = yolov5Model.to(device)\n",
        "yolov5LossFunction = yolov5LossFunction.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p00fCRTiXQOQ",
        "outputId": "cc051d25-fd0a-4f3c-83bc-9abd6340d054"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100:\n",
            "0%,0%,10%,20%,20%,30%,30%,40%,40%,50%,50%,60%,70%,70%,80%,80%,90%,90%,\n",
            "Training Loss: 0.8377\n",
            "Time taken: 0.0min, 51.68099117279053, secs\n",
            "Epoch 2/100:\n",
            "0%,0%,10%,20%,20%,30%,30%,40%,40%,50%,50%,60%,70%,70%,80%,80%,90%,90%,\n",
            "Training Loss: 0.0279\n",
            "Time taken: 0.0min, 42.68564486503601, secs\n",
            "Epoch 3/100:\n",
            "0%,0%,10%,20%,20%,30%,30%,40%,40%,50%,50%,60%,70%,70%,80%,80%,90%,90%,\n",
            "Training Loss: 0.0117\n",
            "Time taken: 0.0min, 42.95397686958313, secs\n",
            "Epoch 4/100:\n",
            "0%,0%,10%,20%,20%,30%,30%,40%,40%,50%,50%,60%,70%,70%,80%,80%,90%,90%,\n",
            "Training Loss: 0.0067\n",
            "Time taken: 0.0min, 42.875529527664185, secs\n",
            "Epoch 5/100:\n",
            "0%,0%,10%,20%,20%,30%,30%,40%,40%,50%,50%,60%,70%,70%,80%,80%,90%,90%,\n",
            "Training Loss: 0.0052\n",
            "Time taken: 0.0min, 42.738624572753906, secs\n",
            "Epoch 6/100:\n",
            "0%,0%,10%,20%,20%,30%,30%,40%,40%,50%,50%,60%,70%,70%,80%,80%,90%,90%,\n",
            "Training Loss: 0.0033\n",
            "Time taken: 0.0min, 42.8049898147583, secs\n",
            "Epoch 7/100:\n",
            "0%,0%,10%,20%,20%,30%,30%,40%,40%,50%,50%,60%,70%,70%,80%,80%,90%,90%,\n",
            "Training Loss: 0.0028\n",
            "Time taken: 0.0min, 42.73208236694336, secs\n",
            "Epoch 8/100:\n",
            "0%,0%,10%,20%,20%,30%,30%,40%,40%,50%,50%,60%,70%,70%,80%,80%,90%,90%,\n",
            "Training Loss: 0.0036\n",
            "Time taken: 0.0min, 42.76790237426758, secs\n",
            "Epoch 9/100:\n",
            "0%,0%,10%,20%,20%,30%,30%,40%,40%,50%,50%,60%,70%,70%,80%,80%,90%,90%,\n",
            "Training Loss: 0.0026\n",
            "Time taken: 0.0min, 42.75577211380005, secs\n",
            "Epoch 10/100:\n",
            "0%,0%,10%,20%,20%,30%,30%,40%,40%,50%,50%,60%,70%,70%,80%,80%,90%,90%,\n",
            "Training Loss: 0.0022\n",
            "Time taken: 0.0min, 42.784536361694336, secs\n",
            "Epoch 11/100:\n",
            "0%,0%,10%,20%,20%,30%,30%,40%,40%,50%,50%,60%,70%,70%,80%,80%,90%,90%,\n",
            "Training Loss: 0.0030\n",
            "Time taken: 0.0min, 42.84817123413086, secs\n",
            "Epoch 12/100:\n",
            "0%,0%,10%,20%,20%,30%,30%,40%,40%,50%,50%,60%,70%,70%,80%,80%,90%,90%,\n",
            "Training Loss: 0.0022\n",
            "Time taken: 0.0min, 42.743409872055054, secs\n",
            "Epoch 13/100:\n",
            "0%,0%,10%,20%,20%,30%,30%,40%,40%,50%,50%,60%,70%,70%,80%,80%,90%,90%,\n",
            "Training Loss: 0.0016\n",
            "Time taken: 0.0min, 42.748881578445435, secs\n",
            "Epoch 14/100:\n",
            "0%,0%,10%,20%,20%,30%,30%,40%,40%,50%,50%,60%,70%,70%,80%,80%,90%,90%,\n",
            "Training Loss: 0.0022\n",
            "Time taken: 0.0min, 42.855276346206665, secs\n",
            "Epoch 15/100:\n",
            "0%,0%,10%,20%,20%,30%,30%,40%,40%,50%,50%,60%,70%,70%,80%,80%,90%,90%,\n",
            "Training Loss: 0.0024\n",
            "Time taken: 0.0min, 42.77470850944519, secs\n",
            "Epoch 16/100:\n",
            "0%,0%,10%,20%,20%,30%,30%,40%,40%,50%,50%,60%,70%,70%,80%,80%,90%,90%,\n",
            "Training Loss: 0.0019\n",
            "Time taken: 0.0min, 42.74148511886597, secs\n",
            "Epoch 17/100:\n",
            "0%,0%,10%,20%,20%,30%,30%,40%,40%,50%,50%,60%,70%,70%,80%,80%,90%,90%,\n",
            "Training Loss: 0.0025\n",
            "Time taken: 0.0min, 42.98367619514465, secs\n",
            "Epoch 18/100:\n",
            "0%,0%,10%,20%,20%,30%,30%,40%,40%,50%,50%,60%,70%,70%,80%,80%,90%,90%,\n",
            "Training Loss: 0.0019\n",
            "Time taken: 0.0min, 42.806573152542114, secs\n",
            "Epoch 19/100:\n",
            "0%,0%,10%,20%,20%,30%,30%,40%,40%,50%,50%,60%,70%,70%,80%,80%,90%,90%,\n",
            "Training Loss: 0.0019\n",
            "Time taken: 0.0min, 42.78111982345581, secs\n",
            "Epoch 20/100:\n",
            "0%,0%,10%,20%,20%,30%,30%,40%,40%,50%,50%,60%,70%,70%,80%,80%,90%,90%,\n",
            "Training Loss: 0.0023\n",
            "Time taken: 0.0min, 42.70667386054993, secs\n",
            "Epoch 21/100:\n",
            "0%,0%,10%,20%,20%,30%,30%,40%,40%,50%,50%,60%,70%,70%,80%,80%,90%,90%,\n",
            "Training Loss: 0.0029\n",
            "Time taken: 0.0min, 42.69568967819214, secs\n",
            "Epoch 22/100:\n",
            "0%,0%,10%,20%,20%,30%,30%,40%,40%,50%,50%,60%,70%,70%,80%,80%,90%,90%,\n",
            "Training Loss: 0.0018\n",
            "Time taken: 0.0min, 42.83827567100525, secs\n",
            "Epoch 23/100:\n",
            "0%,0%,10%,20%,20%,30%,30%,40%,40%,50%,50%,60%,70%,70%,80%,80%,90%,90%,\n",
            "Training Loss: 0.0016\n",
            "Time taken: 0.0min, 42.78562116622925, secs\n",
            "Epoch 24/100:\n",
            "0%,0%,10%,20%,20%,30%,30%,40%,40%,50%,50%,60%,70%,70%,80%,80%,90%,90%,\n",
            "Training Loss: 0.0031\n",
            "Time taken: 0.0min, 42.7826042175293, secs\n",
            "Epoch 25/100:\n",
            "0%,0%,10%,20%,20%,30%,30%,40%,40%,50%,50%,60%,70%,70%,80%,80%,90%,90%,\n",
            "Training Loss: 0.0017\n",
            "Time taken: 0.0min, 42.75570487976074, secs\n",
            "Epoch 26/100:\n",
            "0%,0%,10%,20%,20%,30%,30%,40%,40%,50%,50%,60%,70%,70%,80%,80%,90%,90%,\n",
            "Training Loss: 0.0016\n",
            "Time taken: 0.0min, 42.69545340538025, secs\n",
            "Epoch 27/100:\n",
            "0%,0%,10%,20%,20%,30%,30%,40%,40%,50%,50%,60%,70%,70%,80%,80%,90%,90%,\n",
            "Training Loss: 0.0024\n",
            "Time taken: 0.0min, 42.94851589202881, secs\n",
            "Epoch 28/100:\n",
            "0%,0%,10%,20%,20%,30%,30%,40%,40%,50%,50%,60%,70%,70%,80%,80%,90%,90%,\n",
            "Training Loss: 0.0019\n",
            "Time taken: 0.0min, 42.740095138549805, secs\n",
            "Epoch 29/100:\n",
            "0%,0%,10%,20%,20%,30%,30%,40%,40%,50%,50%,60%,70%,70%,80%,80%,90%,90%,\n",
            "Training Loss: 0.0019\n",
            "Time taken: 0.0min, 42.79442858695984, secs\n",
            "Epoch 30/100:\n",
            "0%,0%,10%,20%,20%,30%,30%,40%,40%,50%,50%,60%,70%,70%,80%,80%,90%,90%,\n",
            "Training Loss: 0.0018\n",
            "Time taken: 0.0min, 42.85156607627869, secs\n",
            "Epoch 31/100:\n",
            "0%,0%,10%,20%,20%,30%,30%,40%,40%,50%,50%,60%,70%,70%,80%,80%,90%,90%,\n",
            "Training Loss: 0.0020\n",
            "Time taken: 0.0min, 42.99068307876587, secs\n",
            "Epoch 32/100:\n",
            "0%,0%,10%,20%,20%,30%,30%,40%,40%,50%,50%,60%,70%,70%,80%,80%,90%,90%,\n",
            "Training Loss: 0.0028\n",
            "Time taken: 0.0min, 42.80075693130493, secs\n",
            "Epoch 33/100:\n",
            "0%,0%,10%,20%,20%,30%,30%,40%,40%,50%,50%,60%,70%,70%,80%,80%,90%,90%,\n",
            "Training Loss: 0.0022\n",
            "Time taken: 0.0min, 42.85321354866028, secs\n",
            "Epoch 34/100:\n",
            "0%,0%,10%,20%,20%,30%,30%,40%,40%,50%,50%,60%,70%,70%,80%,80%,90%,90%,\n",
            "Training Loss: 0.0015\n",
            "Time taken: 0.0min, 42.98964333534241, secs\n",
            "Epoch 35/100:\n",
            "0%,0%,10%,20%,20%,30%,30%,40%,40%,50%,50%,60%,70%,70%,80%,80%,90%,90%,\n",
            "Training Loss: 0.0014\n",
            "Time taken: 0.0min, 42.77049398422241, secs\n",
            "Epoch 36/100:\n",
            "0%,0%,10%,20%,20%,30%,30%,40%,40%,50%,50%,60%,70%,70%,80%,80%,90%,90%,\n",
            "Training Loss: 0.0018\n",
            "Time taken: 0.0min, 42.72260522842407, secs\n",
            "Epoch 37/100:\n",
            "0%,0%,10%,20%,20%,30%,30%,40%,40%,50%,50%,60%,70%,70%,80%,80%,90%,90%,\n",
            "Training Loss: 0.0020\n",
            "Time taken: 0.0min, 42.75439167022705, secs\n",
            "Epoch 38/100:\n",
            "0%,0%,10%,20%,20%,30%,30%,40%,40%,50%,50%,60%,70%,70%,80%,80%,90%,90%,\n",
            "Training Loss: 0.0053\n",
            "Time taken: 0.0min, 43.149982929229736, secs\n",
            "Epoch 39/100:\n",
            "0%,0%,10%,20%,20%,30%,30%,40%,40%,50%,50%,60%,70%,70%,80%,80%,90%,90%,\n",
            "Training Loss: 0.0012\n",
            "Time taken: 0.0min, 43.18256425857544, secs\n",
            "Epoch 40/100:\n",
            "0%,0%,10%,20%,20%,30%,30%,40%,40%,50%,50%,60%,70%,70%,80%,80%,90%,90%,\n",
            "Training Loss: 0.0008\n",
            "Time taken: 0.0min, 43.36111903190613, secs\n",
            "Epoch 41/100:\n",
            "0%,0%,10%,20%,20%,30%,30%,40%,40%,50%,50%,60%,70%,70%,80%,80%,90%,90%,\n",
            "Training Loss: 0.0015\n",
            "Time taken: 0.0min, 43.33724403381348, secs\n",
            "Epoch 42/100:\n",
            "0%,0%,10%,20%,20%,30%,30%,40%,40%,50%,50%,60%,70%,70%,80%,80%,90%,90%,\n",
            "Training Loss: 0.0027\n",
            "Time taken: 0.0min, 43.28685688972473, secs\n",
            "Epoch 43/100:\n",
            "0%,0%,10%,20%,20%,30%,30%,40%,40%,50%,50%,60%,70%,70%,80%,80%,90%,90%,\n",
            "Training Loss: 0.0016\n",
            "Time taken: 0.0min, 43.28926491737366, secs\n",
            "Epoch 44/100:\n",
            "0%,0%,10%,20%,20%,30%,30%,40%,40%,50%,50%,60%,70%,70%,80%,80%,90%,90%,\n",
            "Training Loss: 0.0012\n",
            "Time taken: 0.0min, 43.28507900238037, secs\n",
            "Epoch 45/100:\n",
            "0%,0%,10%,20%,20%,30%,30%,40%,40%,50%,50%,60%,70%,70%,80%,80%,90%,90%,\n",
            "Training Loss: 0.0017\n",
            "Time taken: 0.0min, 43.420573472976685, secs\n",
            "Epoch 46/100:\n",
            "0%,0%,10%,20%,20%,30%,30%,40%,40%,50%,50%,60%,70%,70%,80%,80%,90%,90%,\n",
            "Training Loss: 0.0018\n",
            "Time taken: 0.0min, 43.284348249435425, secs\n",
            "Epoch 47/100:\n",
            "0%,0%,10%,20%,20%,30%,30%,40%,40%,50%,50%,60%,70%,70%,80%,80%,90%,90%,\n",
            "Training Loss: 0.0011\n",
            "Time taken: 0.0min, 43.30639314651489, secs\n",
            "Epoch 48/100:\n",
            "0%,0%,10%,20%,20%,30%,30%,40%,40%,50%,50%,60%,70%,70%,80%,80%,90%,90%,\n",
            "Training Loss: 0.0018\n",
            "Time taken: 0.0min, 43.281874895095825, secs\n",
            "Epoch 49/100:\n",
            "0%,0%,10%,20%,20%,30%,30%,40%,40%,50%,50%,60%,70%,70%,80%,80%,90%,90%,\n",
            "Training Loss: 0.0014\n",
            "Time taken: 0.0min, 43.17818784713745, secs\n",
            "Epoch 50/100:\n",
            "0%,0%,10%,20%,20%,30%,30%,40%,40%,50%,50%,60%,70%,70%,80%,80%,90%,90%,\n",
            "Training Loss: 0.0015\n",
            "Time taken: 0.0min, 43.20761775970459, secs\n",
            "Epoch 51/100:\n",
            "0%,0%,10%,20%,20%,30%,30%,40%,40%,50%,50%,60%,70%,70%,80%,80%,90%,90%,\n",
            "Training Loss: 0.0019\n",
            "Time taken: 0.0min, 43.302412271499634, secs\n",
            "Epoch 52/100:\n",
            "0%,0%,10%,20%,20%,30%,30%,40%,40%,50%,50%,60%,70%,70%,80%,80%,90%,90%,\n",
            "Training Loss: 0.0012\n",
            "Time taken: 0.0min, 43.14268970489502, secs\n",
            "Epoch 53/100:\n",
            "0%,0%,10%,20%,20%,30%,30%,40%,40%,50%,50%,60%,70%,70%,80%,80%,90%,90%,\n",
            "Training Loss: 0.0018\n",
            "Time taken: 0.0min, 43.15219688415527, secs\n",
            "Epoch 54/100:\n",
            "0%,0%,10%,20%,20%,30%,30%,40%,40%,50%,50%,60%,70%,70%,80%,80%,90%,90%,\n",
            "Training Loss: 0.0016\n",
            "Time taken: 0.0min, 43.237282276153564, secs\n",
            "Epoch 55/100:\n",
            "0%,0%,10%,20%,20%,30%,30%,40%,40%,50%,50%,60%,70%,70%,80%,80%,90%,90%,\n",
            "Training Loss: 0.0018\n",
            "Time taken: 0.0min, 43.24059987068176, secs\n",
            "Epoch 56/100:\n",
            "0%,0%,10%,20%,20%,30%,30%,40%,40%,50%,50%,60%,70%,70%,80%,80%,90%,90%,\n",
            "Training Loss: 0.0014\n",
            "Time taken: 0.0min, 43.124879121780396, secs\n",
            "Epoch 57/100:\n",
            "0%,0%,10%,20%,20%,30%,30%,40%,40%,50%,50%,60%,70%,70%,80%,80%,90%,90%,\n",
            "Training Loss: 0.0018\n",
            "Time taken: 0.0min, 43.25692939758301, secs\n",
            "Epoch 58/100:\n",
            "0%,0%,10%,20%,20%,30%,30%,40%,40%,50%,50%,60%,70%,70%,80%,80%,90%,90%,\n",
            "Training Loss: 0.0011\n",
            "Time taken: 0.0min, 43.242181062698364, secs\n",
            "Epoch 59/100:\n",
            "0%,0%,10%,20%,20%,30%,30%,40%,40%,50%,50%,60%,70%,70%,80%,80%,90%,90%,\n",
            "Training Loss: 0.0014\n",
            "Time taken: 0.0min, 43.21792960166931, secs\n",
            "Epoch 60/100:\n",
            "0%,0%,10%,20%,20%,30%,30%,40%,40%,50%,50%,60%,70%,70%,80%,80%,90%,90%,\n",
            "Training Loss: 0.0013\n",
            "Time taken: 0.0min, 43.24702072143555, secs\n",
            "Epoch 61/100:\n",
            "0%,0%,10%,20%,20%,30%,30%,40%,40%,50%,50%,60%,70%,70%,80%,80%,90%,90%,\n",
            "Training Loss: 0.0017\n",
            "Time taken: 0.0min, 43.32879447937012, secs\n",
            "Epoch 62/100:\n",
            "0%,0%,10%,20%,20%,30%,30%,40%,40%,50%,50%,60%,70%,70%,80%,80%,90%,90%,\n",
            "Training Loss: 0.0020\n",
            "Time taken: 0.0min, 43.249032735824585, secs\n",
            "Epoch 63/100:\n",
            "0%,0%,10%,20%,20%,30%,30%,40%,40%,50%,50%,60%,70%,70%,80%,80%,90%,90%,\n",
            "Training Loss: 0.0012\n",
            "Time taken: 0.0min, 43.186036825180054, secs\n",
            "Epoch 64/100:\n",
            "0%,0%,10%,20%,20%,30%,30%,40%,40%,50%,50%,60%,70%,70%,80%,80%,90%,90%,\n",
            "Training Loss: 0.0013\n",
            "Time taken: 0.0min, 43.251858711242676, secs\n",
            "Epoch 65/100:\n",
            "0%,0%,10%,20%,20%,30%,30%,40%,40%,50%,50%,60%,70%,70%,80%,80%,90%,90%,\n",
            "Training Loss: 0.0014\n",
            "Time taken: 0.0min, 43.26275014877319, secs\n",
            "Epoch 66/100:\n",
            "0%,0%,10%,20%,20%,30%,30%,40%,40%,50%,50%,60%,70%,70%,80%,80%,90%,90%,\n",
            "Training Loss: 0.0016\n",
            "Time taken: 0.0min, 43.2615327835083, secs\n",
            "Epoch 67/100:\n",
            "0%,0%,10%,20%,20%,30%,30%,40%,40%,50%,50%,60%,70%,70%,80%,80%,90%,90%,\n",
            "Training Loss: 0.0013\n",
            "Time taken: 0.0min, 43.142728328704834, secs\n",
            "Epoch 68/100:\n",
            "0%,0%,10%,20%,20%,30%,30%,40%,40%,50%,50%,60%,70%,70%,80%,80%,90%,90%,\n",
            "Training Loss: 0.0015\n",
            "Time taken: 0.0min, 43.19336438179016, secs\n",
            "Epoch 69/100:\n",
            "0%,0%,10%,20%,20%,30%,30%,40%,40%,50%,50%,60%,70%,70%,80%,80%,90%,90%,\n",
            "Training Loss: 0.0015\n",
            "Time taken: 0.0min, 43.18841505050659, secs\n",
            "Epoch 70/100:\n",
            "0%,0%,10%,20%,20%,30%,30%,40%,40%,50%,50%,60%,70%,70%,80%,80%,90%,90%,\n",
            "Training Loss: 0.0022\n",
            "Time taken: 0.0min, 43.17814302444458, secs\n",
            "Epoch 71/100:\n",
            "0%,0%,10%,20%,20%,30%,30%,40%,40%,50%,50%,60%,70%,70%,80%,80%,90%,90%,\n",
            "Training Loss: 0.0010\n",
            "Time taken: 0.0min, 43.15381646156311, secs\n",
            "Epoch 72/100:\n",
            "0%,0%,10%,20%,20%,30%,30%,40%,40%,50%,50%,60%,70%,70%,80%,80%,90%,90%,\n",
            "Training Loss: 0.0015\n",
            "Time taken: 0.0min, 43.28236675262451, secs\n",
            "Epoch 73/100:\n",
            "0%,0%,10%,20%,20%,30%,30%,40%,40%,50%,50%,60%,70%,70%,80%,80%,90%,90%,\n",
            "Training Loss: 0.0011\n",
            "Time taken: 0.0min, 43.16049122810364, secs\n",
            "Epoch 74/100:\n",
            "0%,0%,10%,20%,20%,30%,30%,40%,40%,50%,50%,60%,70%,70%,80%,80%,90%,90%,\n",
            "Training Loss: 0.0016\n",
            "Time taken: 0.0min, 43.271315813064575, secs\n",
            "Epoch 75/100:\n",
            "0%,0%,10%,20%,20%,30%,30%,40%,40%,50%,50%,60%,70%,70%,80%,80%,90%,90%,\n",
            "Training Loss: 0.0016\n",
            "Time taken: 0.0min, 43.40058135986328, secs\n",
            "Epoch 76/100:\n",
            "0%,0%,10%,20%,20%,30%,30%,40%,40%,50%,50%,60%,70%,70%,80%,80%,90%,90%,\n",
            "Training Loss: 0.0017\n",
            "Time taken: 0.0min, 43.472163438797, secs\n",
            "Epoch 77/100:\n",
            "0%,0%,10%,20%,20%,30%,30%,40%,40%,50%,50%,60%,70%,70%,80%,80%,90%,90%,\n",
            "Training Loss: 0.0011\n",
            "Time taken: 0.0min, 43.303855180740356, secs\n",
            "Epoch 78/100:\n",
            "0%,0%,10%,20%,20%,30%,30%,40%,40%,50%,50%,60%,70%,70%,80%,80%,90%,90%,\n",
            "Training Loss: 0.0017\n",
            "Time taken: 0.0min, 43.31253504753113, secs\n",
            "Epoch 79/100:\n",
            "0%,0%,10%,20%,20%,30%,30%,40%,40%,50%,50%,60%,70%,70%,80%,80%,90%,90%,\n",
            "Training Loss: 0.0011\n",
            "Time taken: 0.0min, 43.29242444038391, secs\n",
            "Epoch 80/100:\n",
            "0%,0%,10%,20%,20%,30%,30%,40%,40%,50%,50%,60%,70%,70%,80%,80%,90%,90%,\n",
            "Training Loss: 0.0012\n",
            "Time taken: 0.0min, 43.220176696777344, secs\n",
            "Epoch 81/100:\n",
            "0%,0%,10%,20%,20%,30%,30%,40%,40%,50%,50%,60%,70%,70%,80%,80%,90%,90%,\n",
            "Training Loss: 0.0019\n",
            "Time taken: 0.0min, 43.335331201553345, secs\n",
            "Epoch 82/100:\n",
            "0%,0%,10%,20%,20%,30%,30%,40%,40%,50%,50%,60%,70%,70%,80%,80%,90%,90%,\n",
            "Training Loss: 0.0010\n",
            "Time taken: 0.0min, 43.208012104034424, secs\n",
            "Epoch 83/100:\n",
            "0%,0%,10%,20%,20%,30%,30%,40%,40%,50%,50%,60%,70%,70%,80%,80%,90%,90%,\n",
            "Training Loss: 0.0015\n",
            "Time taken: 0.0min, 43.29021978378296, secs\n",
            "Epoch 84/100:\n",
            "0%,0%,10%,20%,20%,30%,30%,40%,40%,50%,50%,60%,70%,70%,80%,80%,90%,90%,\n",
            "Training Loss: 0.0015\n",
            "Time taken: 0.0min, 43.46749567985535, secs\n",
            "Epoch 85/100:\n",
            "0%,0%,10%,20%,20%,30%,30%,40%,40%,50%,50%,60%,70%,70%,80%,80%,90%,90%,\n",
            "Training Loss: 0.0045\n",
            "Time taken: 0.0min, 43.49217104911804, secs\n",
            "Epoch 86/100:\n",
            "0%,0%,10%,20%,20%,30%,30%,40%,40%,50%,50%,60%,70%,70%,80%,80%,90%,90%,\n",
            "Training Loss: 0.0010\n",
            "Time taken: 0.0min, 43.27219581604004, secs\n",
            "Epoch 87/100:\n",
            "0%,0%,10%,20%,20%,30%,30%,40%,40%,50%,50%,60%,70%,70%,80%,80%,90%,90%,\n",
            "Training Loss: 0.0019\n",
            "Time taken: 0.0min, 43.38081693649292, secs\n",
            "Epoch 88/100:\n",
            "0%,0%,10%,20%,20%,30%,30%,40%,40%,50%,50%,60%,70%,70%,80%,80%,90%,90%,\n",
            "Training Loss: 0.0005\n",
            "Time taken: 0.0min, 43.491544246673584, secs\n",
            "Epoch 89/100:\n",
            "0%,0%,10%,20%,20%,30%,30%,40%,40%,50%,50%,60%,70%,70%,80%,80%,90%,90%,\n",
            "Training Loss: 0.0008\n",
            "Time taken: 0.0min, 43.20898365974426, secs\n",
            "Epoch 90/100:\n",
            "0%,0%,10%,20%,20%,30%,30%,40%,40%,50%,50%,60%,70%,70%,80%,80%,90%,90%,\n",
            "Training Loss: 0.0012\n",
            "Time taken: 0.0min, 43.3245267868042, secs\n",
            "Epoch 91/100:\n",
            "0%,0%,10%,20%,20%,30%,30%,40%,40%,50%,50%,60%,70%,70%,80%,80%,90%,90%,\n",
            "Training Loss: 0.0011\n",
            "Time taken: 0.0min, 43.44256615638733, secs\n",
            "Epoch 92/100:\n",
            "0%,0%,10%,20%,20%,30%,30%,40%,40%,50%,50%,60%,70%,70%,80%,80%,90%,90%,\n",
            "Training Loss: 0.0011\n",
            "Time taken: 0.0min, 43.298989057540894, secs\n",
            "Epoch 93/100:\n",
            "0%,0%,10%,20%,20%,30%,30%,40%,40%,50%,50%,60%,70%,70%,80%,80%,90%,90%,\n",
            "Training Loss: 0.0011\n",
            "Time taken: 0.0min, 43.300517320632935, secs\n",
            "Epoch 94/100:\n",
            "0%,0%,10%,20%,20%,30%,30%,40%,40%,50%,50%,60%,70%,70%,80%,80%,90%,90%,\n",
            "Training Loss: 0.0013\n",
            "Time taken: 0.0min, 43.40254545211792, secs\n",
            "Epoch 95/100:\n",
            "0%,0%,10%,20%,20%,30%,30%,40%,40%,50%,50%,60%,70%,70%,80%,80%,90%,90%,\n",
            "Training Loss: 0.0011\n",
            "Time taken: 0.0min, 43.3641254901886, secs\n",
            "Epoch 96/100:\n",
            "0%,0%,10%,20%,20%,30%,30%,40%,40%,50%,50%,60%,70%,70%,80%,80%,90%,90%,\n",
            "Training Loss: 0.0011\n",
            "Time taken: 0.0min, 43.2921199798584, secs\n",
            "Epoch 97/100:\n",
            "0%,0%,10%,20%,20%,30%,30%,40%,40%,50%,50%,60%,70%,70%,80%,80%,90%,90%,\n",
            "Training Loss: 0.0013\n",
            "Time taken: 0.0min, 43.336710691452026, secs\n",
            "Epoch 98/100:\n",
            "0%,0%,10%,20%,20%,30%,30%,40%,40%,50%,50%,60%,70%,70%,80%,80%,90%,90%,\n",
            "Training Loss: 0.0286\n",
            "Time taken: 0.0min, 43.26589751243591, secs\n",
            "Epoch 99/100:\n",
            "0%,0%,10%,20%,20%,30%,30%,40%,40%,50%,50%,60%,70%,70%,80%,80%,90%,90%,\n",
            "Training Loss: 0.0012\n",
            "Time taken: 0.0min, 43.245566606521606, secs\n",
            "Epoch 100/100:\n",
            "0%,0%,10%,20%,20%,30%,30%,40%,40%,50%,50%,60%,70%,70%,80%,80%,90%,90%,\n",
            "Training Loss: 0.0012\n",
            "Time taken: 0.0min, 43.13138771057129, secs\n",
            "Training complete.\n"
          ]
        }
      ],
      "source": [
        "trainedModel = TrainModel(yolov5Model, DLTrain, epochs, optimizer, yolov5LossFunction, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "6cv0JMJ0XTgp"
      },
      "outputs": [],
      "source": [
        "torch.save(trainedModel.state_dict(), 'trained_yolov5Modelv3.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "me0n3Q-OXVwy",
        "outputId": "98b07a47-6abb-438f-d7f6-13f5a0107306"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluateing Model:\n",
            "0%,10%,20%,40%,50%,60%,70%,90%,mAP score on validation set: 0.0000\n",
            "Time taken: 0.0min, 4.427720546722412, secs\n"
          ]
        }
      ],
      "source": [
        "EvaluateModel(yolov5Model, DLVal, device)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.8 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.8"
    },
    "vscode": {
      "interpreter": {
        "hash": "7e1998ff7f8aa20ada591c520b972326324e5ea05489af9e422744c7c09f6dad"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
