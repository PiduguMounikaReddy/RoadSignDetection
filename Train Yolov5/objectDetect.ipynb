{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1682437622768,"user":{"displayName":"anudeep kalitar","userId":"01854914863512508282"},"user_tz":360},"id":"ALnvWznb-Uxx"},"outputs":[],"source":["try:\n","    from google.colab import drive\n","    drive.mount('/content/drive')\n","    import zipfile\n","    with zipfile.ZipFile('/content/drive/MyDrive/DL Project/YoloV5DataSet.zip', 'r') as zip_ref:\n","        zip_ref.extractall('./')\n","except: \n","    print(\"Local Machine\")"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1682437622768,"user":{"displayName":"anudeep kalitar","userId":"01854914863512508282"},"user_tz":360},"id":"MwugvauE-Uxz"},"outputs":[{"name":"stdout","output_type":"stream","text":["Cloning into 'yolov5'...\n","remote: Enumerating objects: 15627, done.\u001b[K\n","remote: Counting objects: 100% (234/234), done.\u001b[K\n","remote: Compressing objects: 100% (168/168), done.\u001b[K\n","remote: Total 15627 (delta 116), reused 138 (delta 66), pack-reused 15393\u001b[K\n","Receiving objects: 100% (15627/15627), 14.65 MiB | 10.19 MiB/s, done.\n","Resolving deltas: 100% (10644/10644), done.\n","zsh:1: command not found: pip\n"]}],"source":["\n","!git clone https://github.com/ultralytics/yolov5.git\n","!pip install -r yolov5/requirements.txt"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3451,"status":"ok","timestamp":1682437626217,"user":{"displayName":"anudeep kalitar","userId":"01854914863512508282"},"user_tz":360},"id":"UD-pI5fE-Uxz"},"outputs":[],"source":["import yaml\n","from pathlib import Path\n","import torch\n","import torch.optim as optim\n","import torch.nn as nn\n","from torch.utils.data import DataLoader\n","from yolov5.utils.dataloaders import LoadImagesAndLabels\n","from yolov5.models.yolo import Model\n","from yolov5.utils.plots import plot_results\n","from yolov5.utils.general import set_logging"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1682437626218,"user":{"displayName":"anudeep kalitar","userId":"01854914863512508282"},"user_tz":360},"id":"rcIp8aLs-Ux0","outputId":"5259b2d4-9997-4bd8-8cd6-edbad218f2db"},"outputs":[],"source":["versionYolo = 'm'\n","sizeOfBatch = 32\n","inputShape = (640, 640)\n","epochs = 100\n","NoAnchors = 3\n","dev = torch.device('CUDA' if torch.cuda.is_available() else 'CPU')\n","print(\"Using the {} device\".format(dev))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1682437626218,"user":{"displayName":"anudeep kalitar","userId":"01854914863512508282"},"user_tz":360},"id":"-bgVKnL3-Ux0"},"outputs":[],"source":["# Load configuration for dataset\n","with open('dataset.yaml') as f:\n","    data1 = yaml.safe_load(f)\n","trainPath, valPath = data1['train'], data1['val']\n","nc, names = data1['nc'], data1['names']"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1682437626218,"user":{"displayName":"anudeep kalitar","userId":"01854914863512508282"},"user_tz":360},"id":"ml1JDNXU-Ux1"},"outputs":[],"source":["#output directory\n","dirSave = Path('runs/train/signboard_exp')\n","(dirSave / 'weights').mkdir(parents=True, exist_ok=True)\n","set_logging(str(dirSave / 'train.log'))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1682437626218,"user":{"displayName":"anudeep kalitar","userId":"01854914863512508282"},"user_tz":360},"id":"V1YSrL7YpJFa"},"outputs":[],"source":["def collateFunc(batch):\n","    maxLen = max([t.shape[0] for _, t, _, _ in batch])\n","    imgs = torch.stack([img for img, _, _, _ in batch])\n","    targets = [torch.cat([t, torch.zeros(maxLen - t.shape[0], t.shape[1])], dim=0) for _, t, _, _ in batch]\n","    targets = torch.stack(targets)\n","    pathvals = [path for _, _, path, _ in batch]\n","    extras = [e for _, _, _, e in batch]\n","\n","    return imgs, targets, pathvals, extras"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":514,"status":"ok","timestamp":1682437626729,"user":{"displayName":"anudeep kalitar","userId":"01854914863512508282"},"user_tz":360},"id":"ePRSLUmi-Ux1","outputId":"3c871b6a-72a1-4934-a8e3-a623c8e5e802"},"outputs":[],"source":["# Load the dataset\n","dsTrain = LoadImagesAndLabels(trainPath, 640, 16, rect=True, pad=0.5)\n","dsVal = LoadImagesAndLabels(valPath, 640, 16, rect=True, pad=0.5)\n","loaderTrain = DataLoader(dsTrain, batch_size=16, collate_fn=collateFunc,shuffle=True, num_workers=4, pin_memory=True)\n","loaderVal = DataLoader(dsVal, batch_size=16, collate_fn=collateFunc,shuffle=False, num_workers=4, pin_memory=True)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":456,"status":"ok","timestamp":1682437627182,"user":{"displayName":"anudeep kalitar","userId":"01854914863512508282"},"user_tz":360},"id":"9RId9PAo-Ux1","outputId":"456741a5-793c-4795-e6ee-0a1c4b192601"},"outputs":[],"source":["print(\"Downloading Weights of yolo5 Verion \", versionYolo)\n","urlWeight = \"https://github.com/ultralytics/yolov5/releases/download/v5.0/yolov5{}.pt\".format(versionYolo)\n","!wget {urlWeight}"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1682437627182,"user":{"displayName":"anudeep kalitar","userId":"01854914863512508282"},"user_tz":360},"id":"cQlM4j-R-Ux1"},"outputs":[],"source":["def yoloCreation(classes, ver):\n","    fileConfig = \"yolov5/models/yolov5{}.yaml\".format(ver)\n","    model = Model(fileConfig, ch=3, nc=classes)\n","    ck = torch.load(f'yolov5{ver}.pt', map_location=dev)\n","    ck_model_dict = ck['model'].state_dict()\n","    compatible_weights = {k: v for k, v in ck_model_dict.items() if k in model.state_dict() and model.state_dict()[k].shape == v.shape}\n","    model.load_state_dict(compatible_weights, strict=False)\n","    model.hyp = ck['model'].hyp\n","    return model\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","def TargeToTensor(targets, sizeOfBatch, anchorsNum, sizeOfGrids):\n","    objTarget = []\n","    boxTarget = []\n","    for sizeOfGrid in sizeOfGrids:\n","        objTarget.append(torch.zeros((sizeOfBatch, anchorsNum, sizeOfGrid, sizeOfGrid, 1)))\n","        boxTarget.append(torch.zeros((sizeOfBatch, anchorsNum, sizeOfGrid, sizeOfGrid, 4)))\n","\n","    for indexBatch, tar in enumerate(targets):\n","        x1, y1, x2, y2 = tar.long()\n","        xcenter, ycenter, width, height = (x1 + x2) / 2, (y1 + y2) / 2, x2 - x1, y2 - y1\n","\n","        for i, sizeOfGrid in enumerate(sizeOfGrids):\n","            xCell, yCell = int(xcenter * sizeOfGrid), int(ycenter * sizeOfGrid)\n","            anchor = 0\n","            try:\n","                objTarget[i][indexBatch, anchor, yCell, xCell, 0] = 1\n","                boxTarget[i][indexBatch, anchor, yCell, xCell] = torch.tensor([xcenter, ycenter, width, height])\n","            except Exception as e:\n","                pass\n","    return objTarget, boxTarget"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","class LossOfSignboard(nn.Module):\n","    def __init__(self, NoAnchors=3):\n","        super(LossOfSignboard, self).__init__()\n","        self.NoAnchors = NoAnchors\n","\n","    def forward(self, preds, targets):\n","        lossObj = torch.tensor(0.0, device=preds[0].device)\n","        lossBox = torch.tensor(0.0, device=preds[0].device)\n","        sizeOfBatch = preds[0].size(0)\n","        sizeOfGrids = [pred.size(2) for pred in preds]\n","        targetObjList, targeBoxList = TargeToTensor(targets, sizeOfBatch, self.NoAnchors, sizeOfGrids)\n","\n","        for i, pred in enumerate(preds):\n","            objTarget = targetObjList[i].to(pred.device)\n","            boxTarget = targeBoxList[i].to(pred.device)\n","\n","            lossObj += nn.BCEWithLogitsLoss()(pred[..., 4:5], objTarget)\n","            lossBox += nn.MSELoss()(pred[..., :4], boxTarget)\n","\n","        totalLoss = lossObj + lossBox\n","        return totalLoss"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Load model\n","classes = 47\n","model = yoloCreation(classes,versionYolo)\n","model = model.to(dev)\n","opt = optim.SGD(model.parameters(), lr=0.01, momentum=0.937, weight_decay=0.0005, nesterov=True)\n","criteria = LossOfSignboard()\n","criteria = criteria.to(dev)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":536},"executionInfo":{"elapsed":2622,"status":"error","timestamp":1682437634421,"user":{"displayName":"anudeep kalitar","userId":"01854914863512508282"},"user_tz":360},"id":"dvUPtqV8-Ux2","outputId":"62d7a7b7-eb82-4098-8bef-865a7dea7b97"},"outputs":[],"source":["\n","epochs = 100\n","bestFit = float('inf')\n","\n","for epoch in range(epochs):\n","    model.train()\n","\n","    for i, (imgs, targets, paths, _) in enumerate(loaderTrain):\n","        imgs = imgs.to(dev).float() / 255.0\n","        targets = targets.to(dev)\n","        pred = model(imgs)\n","        print(\"Pred shape:\")\n","        for p in pred:\n","            print(p.shape)\n","        print(\"Target shape:\", targets.shape)\n","        loss, lossItem = criteria(pred, targets)\n","        lossItem = torch.cat(lossItem)\n","        loss.backward()\n","        opt.step()\n","        opt.zero_grad()\n","    model.eval()\n","\n","    with torch.no_grad():\n","        for i, (imgs, targets, paths, _) in enumerate(loaderVal):\n","            imgs = imgs.to(dev).float() / 255.0\n","            targets = targets.to(dev)\n","\n","            pred = model(imgs)\n","            print(\"Pred shape:\", pred.shape)\n","            print(\"Targets shape:\", targets.shape)\n","            lossVal, lossValItem = criteria(pred, targets)\n","            lossValItem = torch.cat(lossValItem)\n","\n","    # Save best model\n","    if lossVal < bestFit:\n","        bestFit = lossVal\n","        torch.save(model.state_dict(), dirSave / 'weights' / 'best.pt')\n","\n","# Plot training results\n","plot_results(dirSave=dirSave)\n"]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[]},"gpuClass":"premium","kernelspec":{"display_name":"Python 3.10.8 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.8"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"7e1998ff7f8aa20ada591c520b972326324e5ea05489af9e422744c7c09f6dad"}}},"nbformat":4,"nbformat_minor":0}
